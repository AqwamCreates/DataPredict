# [API Reference](../API.md) - Models

If you wonder what are the most high-value use cases that helps with retention and revenue generation this DataPredictâ„¢, you can view them [here](../HighValueProjectTutorials.md)!

| Model Type                     | Count |
|--------------------------------|-------|
| Regression                     | 7     |
| Classification                 | 13    |
| Clustering                     | 8     |
| Deep Reinforcement Learning    | 21    |
| Tabular Reinforcement Learning | 12    |
| Generative                     | 4     |
| Total                          | 65    |

### Legend

| Icon | Name                        | Description                            |
|------|-----------------------------|----------------------------------------|
| ðŸ”°   | Beginner Algorithm         | Commonly taught to beginners.          |
| ðŸ”µ   | Data Efficient             | Require few data to train the model.   |
| ðŸŸ£   | Noise Resistant            | Can handle randomness / unclean data.  |
| ðŸŸ¢   | Online                     | Can adapt real-time.                   |
| ðŸŸ¡   | Session-Adaptive / Offline | Can be retrained each session.         |
| ðŸ”´   | Assumption-Heavy           | Assumes linear / independent features. |

### Note

* For strong deep learning applications, have a look at [DataPredictâ„¢ Neural](https://aqwamcreates.github.io/DataPredict-Neural) (object-oriented) and [DataPredictâ„¢ Axon](https://aqwamcreates.github.io/DataPredict-Axon) (function-oriented) instead. DataPredictâ„¢ is only suitable for general purpose machine, deep and reinforcement learning.

  * Contains most of the deep reinforcement learning and generative algorithms listed here.

  * Includes convolutional, pooling, embedding, dropout and activation layers.

  * Uses reverse-mode automatic differentiation and lazy differentiation evaluation for DataPredictâ„¢ Neural (static graph) and DataPredictâ„¢ Axon (dynamic graph).

* Currently, DataPredictâ„¢ has ~90% (56 out of 65) models with online learning capabilities. By default, most models would perform offline / batch training on the first train, but then switches to online / incremental / sequential after the first train.

* Tabular reinforcement learning models can use optimizers. And yes, I am quite aware that I have overengineered this, but I really want to make this a grand finale before I stop updating DataPredictâ„¢ for a long time.

* No dimensionality reduction algorithms due to not being suitable for game-related use cases. They tend to be computationally expensive and are only useful when a full dataset is collected. This can be offset by choosing proper features and remove the unnecessary ones.

* Going "Gold" on my birthday at 23 January 2026. Probably.

## Regression

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                | Alternate Names | Properties  | Use Cases                                                                                                |
|----------------------------------------------------------------------|-----------------|-------------|----------------------------------------------------------------------------------------------------------|
| [LinearRegression](Models/LinearRegression.md)                       | None            | ðŸ”° ðŸŸ¢ ðŸŸ¡   | General Time-To-Leave Prediction And In-Game Currency Price Generation                                   |
| [PassiveAggressiveRegressor](Models/PassiveAggressiveRegressor.md)   | PA-R            | ðŸŸ¢          | Fast Constrained Time-To-Leave Prediction And In-Game Currency Price Generation                          |
| [SupportVectorRegression](Models/SupportVectorRegression.md)         | SVR             | ðŸ”µ ðŸŸ¡      | Constrained Time-To-Leave Prediction And In-Game Currency Price Generation                               |
| [KNearestNeighboursRegressor](Models/KNearestNeighboursRegressor.md) | KNN-R           | ðŸŸ¢ ðŸŸ¡      | Memory-Based Time-To-Leave Prediction And In-Game Currency Price Generation                             |
| [NormalLinearRegression](Models/NormalLinearRegression.md)*          | None            | ðŸ”µ ðŸŸ¡ ðŸ”´  | Instant Train Time-To-Leave Prediction And In-Game Currency Price Generation                             |
| [BayesianLinearRegression](Models/BayesianLinearRegression.md)*      | None            | ðŸ”µ ðŸŸ¡ ðŸ”´  | Instant Train Time-To-Leave Prediction And In-Game Currency Price Generation With Probability Estimation |
| [QuantileLinearRegression](Models/QuantileLinearRegression.md)*      | None            | ðŸ”µ ðŸŸ¡ ðŸ”´  |Instant Train Time-To-Leave Prediction And In-Game Currency Price Generation With Case Estimation         |

\* The "instant train" models assumes that the features have a linear relationship with the label values, which is almost certainly not true in game-related settings.

 * To use these models, your feature matrix need to be the shape of (n x n).

 * It also recommended to add small independent noise values to each features.

## Classification

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                                | Alternate Names                | Properties     | Use Cases                                                                                                      |
|--------------------------------------------------------------------------------------|--------------------------------|----------------|----------------------------------------------------------------------------------------------------------------|
| [LogisticRegression](Models/LogisticRegression.md)                                   | Perceptron, Sigmoid Regression | ðŸ”° ðŸŸ¢ ðŸŸ¡     | Probability-To-Leave Prediction, Player Churn Prediction, Confidence Prediction                                 |
| [PassiveAggressiveClassifier](Models/PassiveAggressiveClassifier.md)                 | PA-C                           | ðŸŸ¢            | Fast Purchase Likelihood Estimation, Decision Making                                                            |
| [OneClassPassiveAggressiveClassifier](Models/OneClassPassiveAggressiveClassifier.md) | OC-PA-C                        | ðŸŸ¢            |Fast Hacking Detection, Anomaly Detection (Using Single Class Data)                                              |
| [NearestCentroid](Models/NearestCentroid.md)                                         | NC                             | ðŸŸ¢ ðŸŸ¡        | Fast Grouping Or Quick Decision Making                                                                          |
| [KNearestNeighboursClassifier](Models/KNearestNeighboursClassifier.md)               | KNN-C                          | ðŸŸ¢ ðŸŸ¡        | Item Recommendation, Similar Player Matchmaking                                                                 |
| [SupportVectorMachine](Models/SupportVectorMachine.md)                               | SVM                            | ðŸ”µ ðŸŸ¡        | Hacking Detection, Anomaly Detection                                                                            |
| [OneClassSupportVectorMachine](Models/OneClassSupportVectorMachine.md)               | OC-SVM                         | ðŸ”µ ðŸŸ¡        | Hacking Detection, Anomaly Detection (Using Single Class Data)                                                  |
| [NeuralNetwork](Models/NeuralNetwork.md)                                             | Multi-Layer Perceptron         | ðŸŸ¢ ðŸŸ¡        |Decision-Making, Player Behaviour Prediction                                                                     |
| [GaussianNaiveBayes](Models/GaussianNaiveBayes.md)                                   | None                           | ðŸ”µ ðŸŸ¢ ðŸŸ¡ ðŸ”´ | Enemy Data Generation, Player Behavior Categorization (e.g. Cautious Vs. Aggressive), Fast State Classification |
| [MultinomialNaiveBayes](Models/MultinomialNaiveBayes.md)*                            | None                           | ðŸ”µ ðŸŸ¢ ðŸŸ¡ ðŸ”´ |Summoning Next Enemy Type, Inventory Action Prediction, Strategy Profiling Based on Item Usage                   |
| [BernoulliNaiveBayes](Models/BernoulliNaiveBayes.md)*                                | None                           | ðŸ”µ ðŸŸ¢ ðŸŸ¡ ðŸ”´ | Binary Action Prediction (e.g. Jump Or Not), Quick Decision Filters                                             |
| [ComplementNaiveBayes](Models/ComplementNaiveBayes.md)*                              | None                           | ðŸ”µ ðŸŸ¢ ðŸŸ¡ ðŸ”´ | Imbalanced Class Prediction (e.g. Rare Choices, Niche Paths)                                                    |
| [CategoricalNaiveBayes](Models/CategoricalNaiveBayes.md)*                            | None                           | ðŸ”µ ðŸŸ¢ ðŸŸ¡ ðŸ”´ | Player Choice Prediction (e.g. Weapon Type, Character Class, Map Region Selection)                              |

\* "Naive Bayes" models assumes that the features are independent to each other, which is almost certainly not true in game-related settings. Additionally, these models are better as generative models, despite being commonly taught as a classifier.

## Clustering

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                                                                  | Alternate Names | Properties     | Use Cases                                                            |
|------------------------------------------------------------------------------------------------------------------------|-----------------|----------------|----------------------------------------------------------------------|
| [KMeans](Models/KMeans.md)                                                                                             | None            | ðŸ”° ðŸŸ¢ ðŸŸ¡     | Maximizing Area-of-Effect Abilities, Target Grouping                 |
| [FuzzyCMeans](Models/FuzzyCMeans.md)                                                                                   | None            | ðŸŸ¢ ðŸŸ¡         | Overlapping Area-of-Effect Abilities, Overlapping Target Grouping    |
| [KMedoids](Models/KMedoids.md)                                                                                         | None            | ðŸŸ¢ ðŸŸ¡         | Player Grouping Based On Player Locations With Leader Identification |
| [AgglomerativeHierarchical](Models/AgglomerativeHierarchical.md)                                                       | None            | ðŸŸ¢ ðŸŸ¡         | Enemy Data Generation                                                |
| [ExpectationMaximization](Models/ExpectationMaximization.md)                                                           | EM              | ðŸŸ¢ ðŸŸ¡         | Hacking Detection, Anomaly Detection                                 |
| [MeanShift](Models/MeanShift.md)                                                                                       | None            | ðŸŸ£ ðŸŸ¢ ðŸŸ¡      | Boss Spawn Location Search Based On Player Locations                 |
| [AffinityPropagation](Models/AffinityPropagation.md) (Offline Only)                                                    | None            | ðŸŸ¡             | Player Grouping                                                      |
| [DensityBasedSpatialClusteringOfApplicationsWithNoise](Models/DensityBasedSpatialClusteringOfApplicationsWithNoise.md) | DBSCAN          | ðŸŸ£ ðŸŸ¡          | Density Grouping                                                     |

## Deep Reinforcement Learning

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                                                          | Alternate Names               | Properties  | Use Cases                                                                 |
|----------------------------------------------------------------------------------------------------------------|-------------------------------|-------------|---------------------------------------------------------------------------|
| [DeepQLearning](Models/DeepQLearning.md)                                                                       | Deep Q Network                | ðŸ”µ ðŸŸ¢      | Best Self-Learning Player AIs, Best Recommendation Systems                |
| [DeepDoubleQLearningV1](Models/DeepDoubleQLearningV1.md)                                                       | Double Deep Q Network (2010)  | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepDoubleQLearningV2](Models/DeepDoubleQLearningV2.md)                                                       | Double Deep Q Network (2015)  | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepClippedDoubleQLearning](Models/DeepClippedDoubleQLearning.md)                                             | Clipped Deep Double Q Network | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Stable Best Self-Learning Player AIs, Best Recommendation Systems         |
| [DeepStateActionRewardStateAction](Models/DeepStateActionRewardStateAction.md)                                 | Deep SARSA                    | ðŸŸ¢          | Safe Self-Learning Player AIs, Safe Recommendation Systems                |
| [DeepDoubleStateActionRewardStateActionV1](Models/DeepDoubleStateActionRewardStateActionV1.md)                 | Double Deep SARSA             | ðŸŸ¢ ðŸŸ£       | Stable Safe Self-Learning Player AIs, Safe Recommendation Systems         |
| [DeepDoubleStateActionRewardStateActionV2](Models/DeepDoubleStateActionRewardStateActionV2.md)                 | Double Deep SARSA             | ðŸŸ¢ ðŸŸ£      | Stable Safe Self-Learning Player AIs, Safe Recommendation Systems         |
| [DeepExpectedStateActionRewardStateAction](Models/DeepExpectedStateActionRewardStateAction.md)                 | Deep Expected SARSA           | ðŸŸ¢         | Balanced Self-Learning Player AIs, Balanced Recommendation Systems        |
| [DeepDoubleExpectedStateActionRewardStateActionV1](Models/DeepDoubleExpectedStateActionRewardStateActionV1.md) | Double Deep Expected SARSA    | ðŸŸ¢ ðŸŸ£      | Stable Balanced Self-Learning Player AIs, Balanced Recommendation Systems |
| [DeepDoubleExpectedStateActionRewardStateActionV2](Models/DeepDoubleExpectedStateActionRewardStateActionV2.md) | Double Deep Expected SARSA    | ðŸŸ¢ ðŸŸ£      | Stable Balanced Self-Learning Player AIs, Balanced Recommendation Systems |
| [DeepMonteCarloControl](Models/DeepMonteCarloControl.md) (May Need Further Refinement)                         | None                          | ðŸŸ¢         | Online Self-Learning Player AIs                                           |
| [DeepOffPolicyMonteCarloControl](Models/DeepOffPolicyMonteCarloControl.md)                                     | None                          | ðŸŸ¢         | Offline Self-Learning Player AIs                                          |
| [REINFORCE](Models/REINFORCE.md)                                                                               | None                          | ðŸŸ¢         | Reward-Based Self-Learning Player AIs                                     |
| [VanillaPolicyGradient](Models/VanillaPolicyGradient.md) (May Need Further Refinement)                         | VPG                           | ðŸŸ¢         | Baseline-Based Self-Learning Player AIs                                   |
| [ActorCritic](Models/ActorCritic.md)                                                                           | AC                            | ðŸŸ¢         | Critic-Based Self-Learning Player AIs                                     |
| [AdvantageActorCritic](Models/AdvantageActorCritic.md)                                                         | A2C                           | ðŸŸ¢         | Advantage-Based Self-Learning Player AIs                                  |
| [ProximalPolicyOptimization](Models/ProximalPolicyOptimization.md)                                             | PPO                           | ðŸŸ¢         | Industry-Grade And Research-Grade Self-Learning Player And Vehicle AIs    |
| [ProximalPolicyOptimizationClip](Models/ProximalPolicyOptimizationClip.md)                                     | PPO-Clip                      | ðŸŸ¢         | Industry-Grade And Research-Grade Self-Learning Player And Vehicle AIs    |
| [SoftActorCritic](Models/SoftActorCritic.md)                                                                   | SAC                           | ðŸ”µ ðŸŸ£ ðŸŸ¢  | Self-Learning Vehicle AIs                                                 |
| [DeepDeterministicPolicyGradient](Models/DeepDeterministicPolicyGradient.md)                                   | DDPG                          | ðŸŸ¢         | Self-Learning Vehicle AIs                                                 |
| [TwinDelayedDeepDeterministicPolicyGradient](Models/TwinDelayedDeepDeterministicPolicyGradient.md)             | TD3                           | ðŸŸ¢         | Self-Learning Vehicle AIs                                                 |

## Tabular Reinforcement Learning

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                                                                              | Alternate Names           | Properties  | Use Cases                       |
|------------------------------------------------------------------------------------------------------------------------------------|---------------------------|-------------|---------------------------------|
| [TabularQLearning](Models/TabularQLearning.md)                                                                                     | Q-Learning                | ðŸ”° ðŸ”µ ðŸŸ¢   | Best Self-Learning Grid AIs     |
| [TabularDoubleQLearningV1](Models/TabularDoubleQLearningV1.md)                                                                     | Double Q-Learning (2010)  | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Best Self-Learning Grid AIs     |
| [TabularDoubleQLearningV2](Models/TabularDoubleQLearningV2.md)                                                                     | Double Q-Learning (2015)  | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Best Self-Learning Grid AIs     |
| [TabularClippedDoubleQLearning](Models/TabularClippedDoubleQLearning.md)                                                           | Clipped Double Q-Learning | ðŸ”µ ðŸŸ£ ðŸŸ¢   | Best Self-Learning Grid AIs     |
| [TabularStateActionRewardStateAction](Models/TabularStateActionRewardStateAction.md) (May Need Further Refinement)                 | SARSA                     | ðŸ”° ðŸŸ¢       | Safe Self-Learning Grid AIs     |
| [TabularDoubleStateActionRewardStateActionV1](Models/TabularDoubleStateActionRewardStateActionV1.md) (May Need Further Refinement) | Double SARSA              | ðŸŸ¢ ðŸŸ£       | Safe Self-Learning Grid AIs     |
| [TabularDoubleStateActionRewardStateActionV2](Models/TabularDoubleStateActionRewardStateActionV2.md) (May Need Further Refinement) | Double SARSA              | ðŸŸ¢ ðŸŸ£       | Safe Self-Learning Grid AIs     |
| [TabularExpectedStateActionRewardStateAction](Models/TabularExpectedStateActionRewardStateAction.md)                               | Expected SARSA            | ðŸŸ¢           | Balanced Self-Learning Grid AIs |
| [TabularDoubleExpectedStateActionRewardStateActionV1](Models/TabularDoubleExpectedStateActionRewardStateActionV1.md)               | Double Expected SARSA     | ðŸŸ¢ ðŸŸ£       | Balanced Self-Learning Grid AIs |
| [TabularDoubleExpectedStateActionRewardStateActionV2](Models/TabularDoubleExpectedStateActionRewardStateActionV2.md)               | Double Expected SARSA     | ðŸŸ¢ ðŸŸ£       | Balanced Self-Learning Grid AIs |
| [TabularMonteCarloControl](Models/TabularMonteCarloControl.md)                                                                     | MC                        | ðŸŸ¢          | Online Self-Learning Grid AIs   |
| [TabularOffPolicyMonteCarloControl](Models/TabularOffPolicyMonteCarloControl.md)                                                   | Off-Policy MC             | ðŸŸ¢          | Offline Self-Learning Grid AIs  |

## Generative

> ðŸ”° Beginner Algorithm ðŸ”µ Data Efficient ðŸŸ£ Noise Resistant ðŸŸ¢ Onlineâ€ƒðŸŸ¡ Session-Adaptive / Offlineâ€ƒðŸ”´ Assumption-Heavy

| Model                                                                                                              | Alternate Names | Properties | Use Cases                                 |
|--------------------------------------------------------------------------------------------------------------------|-----------------|------------| ------------------------------------------|
| [GenerativeAdversarialNetwork](Models/GenerativeAdversarialNetwork.md)                                             | GAN             | ðŸŸ¢ ðŸŸ¡     | Enemy Data Generation                     |
| [ConditionalGenerativeAdversarialNetwork](Models/ConditionalGenerativeAdversarialNetwork.md)                       | CGAN            | ðŸŸ¢ ðŸŸ¡     | Conditional Enemy Data Generation         |
| [WassersteinGenerativeAdversarialNetwork](Models/WassersteinGenerativeAdversarialNetwork.md)                       | WGAN            | ðŸŸ¢ ðŸŸ¡     | Stable Enemy Data Generation              |
| [ConditionalWassersteinGenerativeAdversarialNetwork](Models/ConditionalWassersteinGenerativeAdversarialNetwork.md) | CWGAN           | ðŸŸ¢ ðŸŸ¡      | Stable Conditional Enemy Data Generation |

## BaseModels

[BaseModel](Models/BaseModel.md)

[NaiveBayesBaseModel](Models/NaiveBayesBaseModel.md)

[GradientMethodBaseModel](Models/GradientMethodBaseModel.md)

[IterativeMethodBaseModel](Models/IterativeMethodBaseModel.md)

[DeepReinforcementLearningBaseModel](Models/DeepReinforcementLearningBaseModel.md)

[DeepReinforcementLearningActorCriticBaseModel](Models/DeepReinforcementLearningActorCriticBaseModel.md)

[TabularReinforcementLearningBaseModel](Models/TabularReinforcementLearningBaseModel.md)

[GenerativeAdversarialNetworkBaseModel](GenerativeAdversarialNetworkBaseModel.md)
